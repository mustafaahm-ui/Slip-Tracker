import streamlit as st
import cv2
import numpy as np
import pandas as pd
import tempfile
import os
from ultralytics import YOLO
import time
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase
import av

# --- Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø© ---
st.set_page_config(page_title="Tractor Slip Analyzer", layout="wide", page_icon="ğŸšœ")

# --- ØªÙ‡ÙŠØ¦Ø© Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø°Ø§ÙƒØ±Ø© ---
if 'v_theo' not in st.session_state:
    st.session_state.v_theo = 0.0
if 'ppm' not in st.session_state:
    st.session_state.ppm = 0.0  # Pixels per meter

# --- Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø© ---
@st.cache_resource
def load_model():
    return YOLO('best.pt')

try:
    model = load_model()
except:
    st.error("Model 'best.pt' not found!")
    st.stop()

# --- ÙØ¦Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ù…Ø¨Ø§Ø´Ø± (WebRTC) ---
class TractorTracker(VideoTransformerBase):
    def __init__(self):
        self.ppm = st.session_state.ppm
        self.v_theo = st.session_state.v_theo
        self.mode = "calibrating" if self.v_theo == 0 else "measuring"
        self.prev_y = None
        self.last_time = time.time()
        self.dist_accumulated = 0
        self.model = model

    def transform(self, frame):
        img = frame.to_ndarray(format="bgr24")
        h, w, _ = img.shape
        current_time = time.time()
        
        # ØªØªØ¨Ø¹ Ø§Ù„ÙƒØ§Ø¦Ù†Ø§Øª
        results = self.model.track(img, persist=True, verbose=False)
        
        curr_speed_kmh = 0.0
        slip_ratio = 0.0
        
        if results[0].boxes.id is not None:
            box = results[0].boxes.xyxy[0].cpu().numpy()
            center_y = int((box[1] + box[3]) / 2)
            
            # Ø±Ø³Ù… Ø§Ù„Ù…Ø±Ø¨Ø¹
            cv2.rectangle(img, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), (0, 255, 0), 2)
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø³Ø±Ø¹Ø©
            if self.prev_y is not None and self.ppm > 0:
                pixel_move = abs(center_y - self.prev_y)
                time_diff = current_time - self.last_time
                
                if time_diff > 0:
                    dist_m = pixel_move / self.ppm
                    speed_ms = dist_m / time_diff
                    curr_speed_kmh = speed_ms * 3.6
                    
                    # ØªÙ†Ø¹ÙŠÙ… Ø§Ù„Ù‚Ø±Ø§Ø¡Ø© (ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ù‚ÙØ²Ø§Øª ØºÙŠØ± Ø§Ù„Ù…Ù†Ø·Ù‚ÙŠØ©)
                    if curr_speed_kmh < 30: 
                        self.dist_accumulated += dist_m

            self.prev_y = center_y
            self.last_time = current_time
        
        # --- Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù„Ù‰ Ø§Ù„Ø´Ø§Ø´Ø© ---
        
        # 1. ÙˆØ¶Ø¹ Ø§Ù„Ù…Ø¹Ø§ÙŠØ±Ø© (Ø§Ù„Ø£Ø³ÙÙ„Øª)
        if self.mode == "calibrating":
            cv2.putText(img, "MODE: REFERENCE RUN (ASPHALT)", (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
            cv2.putText(img, f"Current Speed: {curr_speed_kmh:.1f} km/h", (20, 80), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)
            
            # Ù‡Ù†Ø§ Ù†Ù‚ÙˆÙ… ÙÙ‚Ø· Ø¨Ø¹Ø±Ø¶ Ø§Ù„Ø³Ø±Ø¹Ø©ØŒ ÙˆØ§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø³ÙŠØ£Ø®Ø° Ø§Ù„Ù‚ÙŠÙ…Ø© ÙŠØ¯ÙˆÙŠØ§Ù‹ Ø£Ùˆ Ù†Ø·ÙˆØ± ÙƒÙˆØ¯Ø§Ù‹ Ù„Ø­ÙØ¸Ù‡Ø§
            
        # 2. ÙˆØ¶Ø¹ Ø§Ù„Ù‚ÙŠØ§Ø³ (Ø§Ù„Ø­Ù‚Ù„)
        else:
            if self.v_theo > 0:
                slip_ratio = ((self.v_theo - curr_speed_kmh) / self.v_theo) * 100
            
            # Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ø­Ø§Ù„Ø©
            color = (0, 255, 0)
            status = "Safe"
            if slip_ratio > 15: color, status = (0, 255, 255), "Warning"
            if slip_ratio > 20: color, status = (0, 0, 255), "Slip!"

            cv2.rectangle(img, (0, 0), (350, 150), (0, 0, 0), -1)
            cv2.putText(img, f"V_Act: {curr_speed_kmh:.1f} km/h", (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
            cv2.putText(img, f"V_Ref: {self.v_theo:.1f} km/h", (10, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (200, 200, 200), 1)
            cv2.putText(img, f"SLIP: {slip_ratio:.1f}%", (10, 130), cv2.FONT_HERSHEY_SIMPLEX, 1.2, color, 3)

        return img

# --- ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ---
st.title("ğŸšœ Live Tractor Slip Detector")

# Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…ØµØ¯Ø±
source_option = st.radio("Select Input Source:", ("ğŸ“‚ Upload Video", "ğŸ“· Live Camera (WebRTC)"))

# --- Ù‚Ø³Ù… Ø§Ù„Ù…Ø¹Ø§ÙŠØ±Ø© (Ù…Ø¨Ø³Ø·) ---
with st.expander("âš™ï¸ Step 1: Calibration (Pixels per Meter)", expanded=True):
    st.write("Draw lines on screen conceptually. If distance between markers is 2m:")
    real_dist = st.number_input("Real Distance (m)", value=2.0)
    pixel_dist = st.number_input("Pixels on screen (Estimate)", value=200)
    
    if st.button("Set PPM"):
        st.session_state.ppm = pixel_dist / real_dist
        st.success(f"PPM Set: {st.session_state.ppm}")

# --- Ù‚Ø³Ù… Ø§Ù„Ø³Ø±Ø¹Ø© Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠØ© ---
with st.expander("ğŸï¸ Step 2: Set Reference Speed (Asphalt)", expanded=True):
    col1, col2 = st.columns(2)
    manual_v = col1.number_input("Enter V_theo manually (if known)", value=5.4)
    if col1.button("Set V_theo"):
        st.session_state.v_theo = manual_v
        st.success(f"Reference Speed Fixed: {manual_v} km/h")
    
    col2.metric("Current V_theo", f"{st.session_state.v_theo} km/h")

# --- Ø§Ù„Ø´Ø§Ø´Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ---
st.markdown("### ğŸ“º Monitoring Screen")

if source_option == "ğŸ“· Live Camera (WebRTC)":
    st.info("Ensure you allow camera access. Works on Mobile & PC.")
    webrtc_streamer(key="tractor", video_transformer_factory=TractorTracker)

else: # Upload Video
    uploaded_video = st.file_uploader("Upload Video", type=['mp4', 'avi'])
    if uploaded_video:
        tfile = tempfile.NamedTemporaryFile(delete=False)
        tfile.write(uploaded_video.read())
        cap = cv2.VideoCapture(tfile.name)
        
        st_frame = st.empty()
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret: break
            
            # Ù†ÙØ³ Ù…Ù†Ø·Ù‚ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ù‡Ù†Ø§ (Ù…Ø¨Ø³Ø· Ù„Ù„Ø¹Ø±Ø¶)
            results = model.track(frame, persist=True, verbose=False)
            if results[0].boxes.id is not None:
                box = results[0].boxes.xyxy[0].cpu().numpy()
                cv2.rectangle(frame, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), (0, 255, 0), 2)
            
            st_frame.image(frame, channels="BGR")